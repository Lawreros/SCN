{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCN Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from gen_utils.sr_gen import sr_gen # Custom class for image generation/organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCN(nn.Module):\n",
    "    def __init__(self,sy,sg, model_file=False, train=True):\n",
    "        super().__init__()\n",
    "        C = 5\n",
    "        L = 5\n",
    "\n",
    "        Dx = torch.normal(0,1, size = (25,128))\n",
    "        Dy = torch.normal(0,1, size = (100,128))\n",
    "        I = torch.eye(128)\n",
    "\n",
    "        self.conv = nn.Conv2d(1,100,9, bias = False, stride =1, padding = 6)\n",
    "        self.mean2 = nn.Conv2d(1,1,13, bias = False, stride = 1, padding = 6)\n",
    "        self.diffms = nn.Conv2d(1,25,9, bias=False, stride = 1, padding=6)\n",
    "\n",
    "        self.wd = nn.Conv2d(100,128,1,bias = False, stride = 1)\n",
    "        self.usd1 = nn.Conv2d(128, 128, 1, bias = False, stride=1)\n",
    "        self.ud = nn.Conv2d(128,25,1,bias=False,stride=1)\n",
    "        self.addp = nn.Conv2d(16,1,1, bias = False, stride = 1)\n",
    "\n",
    "        if train: #If you are currently training the model\n",
    "            self.mean2.weight = torch.nn.Parameter(self.create_gaus(13), requires_grad = False)\n",
    "            self.diffms.weight = torch.nn.Parameter(self.create_diffms(9,5),requires_grad=False)\n",
    "            self.wd.weight = torch.nn.Parameter(self.expand_params(C*Dy.T), requires_grad=True)\n",
    "            self.usd1.weight = torch.nn.Parameter(self.expand_params(I - torch.matmul(Dy.T,Dy)), requires_grad=True)\n",
    "            self.ud.weight = torch.nn.Parameter(self.expand_params((1/(C*L))*Dx), requires_grad=True)\n",
    "            self.addp.weight = torch.nn.Parameter(torch.ones(1,16,1,1)*0.06, requires_grad=True)\n",
    "\n",
    "        else:\n",
    "            self.conv.weight = torch.nn.Parameter(torch.ones(100,1,9,9),requires_grad=False)\n",
    "            self.mean2.weight = torch.nn.Parameter(self.create_gaus(13),requires_grad=False)\n",
    "            self.diffms.weight = torch.nn.Parameter(self.create_diffms(9,5),requires_grad=False)\n",
    "            self.wd.weight = torch.nn.Parameter(self.expand_params(C*Dy.T),requires_grad=False)\n",
    "            self.usd1.weight = torch.nn.Parameter(self.expand_params(I - torch.matmul(Dy.T,Dy)),requires_grad=False)\n",
    "            self.ud.weight = torch.nn.Parameter(self.expand_params((1/(C*L))*Dx),requires_grad=False)\n",
    "            self.addp.weight = torch.nn.Parameter(torch.ones(1,16,1,1)*0.06,requires_grad=False)\n",
    "\n",
    "\n",
    "    def forward(self, x, k, sy=9, sg=5):\n",
    "        im_mean = self.mean2(x)\n",
    "        # print(f'im_mean shape {im_mean.shape}')\n",
    "        diffms = self.diffms(x)\n",
    "        # print(f'diffms shape: {diffms.shape}')\n",
    "\n",
    "        n, c, h, w = x.shape\n",
    "        # y = torch.zeros(n, 100, h-8, w-8)\n",
    "        x = self.conv(x)\n",
    "        # print(f'post conv shape {x.shape}')\n",
    "        #print(f'conv max {x.max()}')\n",
    "        x=x+1\n",
    "\n",
    "        x = x/torch.linalg.vector_norm(x, ord=2, dim=1, keepdim=True)\n",
    "        # print(f'post vector norm shape: {x.shape}')\n",
    "        #print(f'postnorm max {x.max()}')\n",
    "\n",
    "        x = self.wd(x)\n",
    "        #print(f'conv wd {x.max()}')\n",
    "        z = self.ShLU(x,1)\n",
    "        #print(f'conv SHLU {x.max()}')\n",
    "\n",
    "        # Go through LISTA\n",
    "        for i in range(k):\n",
    "            z = self.ShLU(self.usd1(z)+x,1)\n",
    "\n",
    "        x = self.ud(z)\n",
    "        #print(f'ud max {x.max()}')\n",
    "        # print(f'post ud shape {x.shape}')\n",
    "        x = (x/torch.linalg.vector_norm(x, ord=2, dim=1, keepdim=True))*torch.linalg.vector_norm(diffms, ord=2, dim=1, keepdim=True)*1.1\n",
    "        # print(f'prereassembled x shape {x.shape}')\n",
    "        x = self.reassemble2(x,im_mean,4)\n",
    "        # print(f'reassembled x shape {x.shape}')\n",
    "        x = self.addp(x)\n",
    "        #print(f'x.reassemble.max = {x.max()}')\n",
    "        x = x+im_mean\n",
    "\n",
    "        return x\n",
    "\n",
    "    def reassemble2(self, x, im_mean, patch_size):\n",
    "        img = im_mean\n",
    "        s, c, h, w = img.shape\n",
    "        \n",
    "        # img_stack=torch.zeros(s,25,h,w)\n",
    "        img_stack=torch.zeros(s,16,h,w)\n",
    "        \n",
    "        #go through every sample and reassemble the image\n",
    "        for q in range(x.shape[0]):\n",
    "            filt = 0\n",
    "            for ii in range(patch_size-1, -1, -1):\n",
    "                for jj in range(patch_size-1, -1, -1):\n",
    "                    img_stack[q,filt,:,:] = x[q,filt,jj:(jj+h), ii:(ii+w)]\n",
    "                    filt+=1\n",
    "        \n",
    "        return img_stack\n",
    "    \n",
    "    def create_diffms(self, kern_size, sy=5):\n",
    "        diffms = torch.zeros(sy**2,1,kern_size,kern_size)\n",
    "        \n",
    "        neg = -1*(1/(sy**2))\n",
    "        pos = 1+neg\n",
    "        \n",
    "        border = int((kern_size-sy)/2)\n",
    "        base = torch.zeros(sy,sy)+neg\n",
    "        cnt=0\n",
    "        \n",
    "        for i in range(sy**2):\n",
    "            base = torch.zeros(sy**2)+neg\n",
    "            base[cnt]=pos\n",
    "            diffms[i,0,border:(kern_size-border),border:(kern_size-border)] = base.reshape([sy,sy])\n",
    "            cnt+=1\n",
    "        return diffms\n",
    "    \n",
    "    \n",
    "    def create_gaus(self, kern_size, sy=9,std=2.15):\n",
    "        n = torch.arange(0,sy)-(sy-1.0)/2.0\n",
    "        sig2 = 2 * std * std\n",
    "        gkern1d = torch.exp(-n ** 2 / sig2)\n",
    "        gkern1d = gkern1d/torch.sum(gkern1d)\n",
    "        #print(gkern1d.shape)\n",
    "        gkern2d = torch.outer(gkern1d, gkern1d)\n",
    "    \n",
    "\n",
    "        # Wrap in zeros, if kern_size > sy\n",
    "        gaussian_filter = torch.zeros(1,1,kern_size,kern_size)\n",
    "        border = int((kern_size-sy)/2)\n",
    "        gaussian_filter[0,0,border:(kern_size-border),border:(kern_size-border)] = gkern2d#(sy,std=std)\n",
    "        #print(gaussian_filter.shape)\n",
    "        return gaussian_filter\n",
    "        \n",
    "    \n",
    "    def fixed_positions(self, tens, mult, sg):\n",
    "        f, _ , h, w = tens.shape\n",
    "        new_filt = torch.zeros(f*mult, 1, sg,sg)\n",
    "        cnt = 0\n",
    "        filt = 0\n",
    "        \n",
    "        for filt in range(f):\n",
    "            for j in range((sg-w)+1):\n",
    "                for i in range((sg-h)+1):\n",
    "                    new_filt[cnt,0,i:i+h,j:j+w] = tens[filt]\n",
    "                    cnt+=1\n",
    "        return new_filt\n",
    "    \n",
    "    def expand_params(self,tens):\n",
    "        return torch.unsqueeze(torch.unsqueeze(tens,2),3)\n",
    "    \n",
    "    def ShLU(self,a, th):\n",
    "        return torch.sign(a)*torch.maximum(abs(a)-th, torch.tensor(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Optimization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SCN(9,5,train=True)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    [\n",
    "        {\"params\": net.addp.parameters()},#, \"lr\": 0.0002, \"momentum\": 0.00005},\n",
    "        {\"params\": net.conv.parameters()},#, \"lr\": 0.0003, \"momentum\": 0.0001},\n",
    "        {\"params\": net.wd.parameters()},\n",
    "        {\"params\": net.usd1.parameters()},\n",
    "        {\"params\": net.ud.parameters()},\n",
    "    ],\n",
    "    lr=0.00007, momentum = 0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_train = sr_gen('./data/raw/nii_sub_HR/','./data/raw/HR_output/','./data/raw/LR_output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = sr_train.get_template()\n",
    "temp[\"patch\"]=20\n",
    "temp[\"step\"]=10\n",
    "temp.save_template(temp)\n",
    "\n",
    "sr_train.run(clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: There's not reasing I can't combine the Dataset class and my custom class into one thing\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sr_class):\n",
    "        self.sr_class = sr_class\n",
    "\n",
    "        # In case I forget to run match_altered before pulling the class\n",
    "        if not sr_class.HR_files:\n",
    "            sr_class.match_altered(update=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sr_class.HR_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        Y, X = self.sr_class.load_image_pair(index)\n",
    "        X = torch.unsqueeze(torch.tensor(X, dtype=torch.float32),0)\n",
    "        Y = torch.unsqueeze(torch.tensor(Y, dtype=torch.float32),0)\n",
    "\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 2}\n",
    "\n",
    "training_set = Dataset(sr_train)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "# Loop over epochs\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "    losses = []\n",
    "    losses_per = []\n",
    "\n",
    "    # Training\n",
    "    count = 0\n",
    "    for inp, goal in training_generator:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(inp,2) # the 2 is the number of iterations in the LISTA network\n",
    "        print(output.shape)\n",
    "        output = torch.clamp(output, 0, 255)\n",
    "\n",
    "        loss = criterion(output,goal)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'loss = {loss.item()}')\n",
    "        losses.append(loss.item())\n",
    "        print(f'mini-batch # {count}, mean loss = {sum(losses)/len(losses)}')\n",
    "        count = count+1\n",
    "\n",
    "    torch.save(net.state_dict(), f'./MRI_save_{epoch}.p')\n",
    "    print(f'\\n\\n epoch {epoch}, loss mean: {sum(losses)/len(losses)}, loss: {min(losses)}-{max(losses)}\\n')\n",
    "\n",
    "    # Give computer time to cool down\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('3.8.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "539b544e2c3fdc58492248d082a132f5e0b4fea63e914fb274c32873997cf2f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
